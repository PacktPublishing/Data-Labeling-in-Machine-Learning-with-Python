{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 2516.58it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 3269.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [ 0 -1 -1]\n",
      " [-1  1 -1]]\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]]\n",
      "(2, 3)\n",
      "(2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LabelingFunction, PandasLFApplier\n",
    "import nltk \n",
    "\n",
    "from snorkel.labeling import labeling_function \n",
    "\n",
    "from snorkel.labeling import PandasLFApplier \n",
    "\n",
    "from snorkel.labeling import LFAnalysis \n",
    "\n",
    "from nltk.corpus import movie_reviews \n",
    "\n",
    "import nltk \n",
    "\n",
    "import random \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "from snorkel.labeling import LabelingFunction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the constants\n",
    "ABSTAIN = -1\n",
    "POS = 0\n",
    "NEG = 1\n",
    "\n",
    "# Create a DataFrame with more data\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'review': [\n",
    "        \"This movie was absolutely wonderful!\",\n",
    "        \"The film was terrible and boring.\",\n",
    "        \"I have mixed feelings about the movie.\",\n",
    "        \"I have no opinion about the movie.\",\n",
    "        \"The movie was fantastic and exciting!\",\n",
    "        \"I didn't like the movie, it was too slow.\",\n",
    "        \"The movie was okay, not great but not bad either.\",\n",
    "        \"The movie was confusing and dull.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Split the DataFrame into a training set and a test set\n",
    "df_train = df.iloc[:6]  # First 6 records for training\n",
    "df_test = df.iloc[6:]  # Remaining records for testing\n",
    "\n",
    "# Define the true labels for the test set\n",
    "Y_test = [ABSTAIN, NEG]  # Replace this with the actual labels\n",
    "\n",
    "# Convert Y_test to a NumPy array\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "@labeling_function()\n",
    "def lf_positive_review(x):\n",
    "    return POS if 'wonderful' in x.review or 'fantastic' in x.review else ABSTAIN \n",
    "\n",
    "@labeling_function()\n",
    "def lf_negative_review(x):\n",
    "    return NEG if 'terrible' in x.review or 'boring' in x.review or 'slow' in x.review or 'dull' in x.review else ABSTAIN \n",
    "\n",
    "@labeling_function()\n",
    "def lf_neutral_review(x):\n",
    "    return ABSTAIN if 'mixed feelings' in x.review or 'no opinion' in x.review or 'okay' in x.review else ABSTAIN \n",
    "\n",
    "# Apply the labeling functions to the training set and the test set\n",
    "lfs = [lf_positive_review, lf_negative_review, lf_neutral_review]\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)\n",
    "\n",
    "print(L_train)\n",
    "print(L_test)\n",
    "print(L_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter, LabelModel\n",
    "majority_model = MajorityLabelVoter()\n",
    "majority_model.predict(L=L_train)\n",
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print( majority_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1 -1 -1  0  1]\n"
     ]
    }
   ],
   "source": [
    "preds_train = majority_model.predict(L=L_train)\n",
    "print(preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.058]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      " 46%|████▌     | 231/500 [00:00<00:00, 2306.08epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2896.35epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(label_model_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1 -1 -1  0  1]\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the training data\n",
    "Y_train_pred = label_model.predict(L=L_train)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_positive_review</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_negative_review</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_neutral_review</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_positive_review  0      [0]  0.333333       0.0        0.0\n",
       "lf_negative_review  1      [1]  0.333333       0.0        0.0\n",
       "lf_neutral_review   2       []  0.000000       0.0        0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                     review  predicted_label\n",
      "0   1       This movie was absolutely wonderful!                0\n",
      "1   2          The film was terrible and boring.                1\n",
      "2   3     I have mixed feelings about the movie.               -1\n",
      "3   4         I have no opinion about the movie.               -1\n",
      "4   5      The movie was fantastic and exciting!                0\n",
      "5   6  I didn't like the movie, it was too slow.                1\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the predicted labels\n",
    "df_train_pred = df_train.copy()\n",
    "df_train_pred['predicted_label'] = Y_train_pred\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----end---\n",
    "not required below cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98522167 0.01477833]\n",
      " [0.01477833 0.98522167]\n",
      " [0.5        0.5       ]\n",
      " [0.5        0.5       ]\n",
      " [0.98522167 0.01477833]\n",
      " [0.01477833 0.98522167]]\n"
     ]
    }
   ],
   "source": [
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "print(probs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                     review\n",
      "0   1       This movie was absolutely wonderful!\n",
      "1   2          The film was terrible and boring.\n",
      "4   5      The movie was fantastic and exciting!\n",
      "5   6  I didn't like the movie, it was too slow.\n",
      "[[0.98522167 0.01477833]\n",
      " [0.01477833 0.98522167]\n",
      " [0.98522167 0.01477833]\n",
      " [0.01477833 0.98522167]]\n"
     ]
    }
   ],
   "source": [
    "print(df_train_filtered)\n",
    "print(probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1]\n",
      "['This movie was absolutely wonderful!', 'The film was terrible and boring.', 'The movie was fantastic and exciting!', \"I didn't like the movie, it was too slow.\"]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "X_train = df_train_filtered['review'].tolist()\n",
    "X_test = df_test['review'].tolist()\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)\n",
    "print(preds_train_filtered)\n",
    "print(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
