{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Recording...\n",
      "Model Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to capture real-time audio\n",
    "def capture_audio(duration=5, sampling_rate=44100):\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(int(sampling_rate * duration), samplerate=sampling_rate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data.flatten()\n",
    "\n",
    "\n",
    "\n",
    "# Function to collect training data\n",
    "def collect_training_data(num_samples=10, label=0):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        input(\"Press Enter and speak for a few seconds...\")\n",
    "        audio_sample = capture_audio()\n",
    "        X.append(audio_sample)\n",
    "        y.append(label)\n",
    "\n",
    "    return np.vstack(X), np.array(y)\n",
    "\n",
    "# Main program\n",
    "class VoiceClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier()\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "# Collect positive samples (voice)\n",
    "positive_X, positive_y = collect_training_data(num_samples=10, label=1)\n",
    "\n",
    "# Collect negative samples (background noise or non-voice)\n",
    "negative_X, negative_y = collect_training_data(num_samples=10, label=0)\n",
    "\n",
    "# Combine and shuffle the data\n",
    "X = np.vstack([positive_X, negative_X])\n",
    "y = np.concatenate([positive_y, negative_y])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the voice classifier model\n",
    "voice_classifier = VoiceClassifier()\n",
    "voice_classifier.train(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = voice_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (1.2.0)\n",
      "Requirement already satisfied: sounddevice in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (0.4.6)\n",
      "Requirement already satisfied: scikit-learn in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (1.1.3)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (from sounddevice) (1.15.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: pycparser in /Users/sudachk/Library/Python/3.9/lib/python/site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib sounddevice scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['voice_classifier_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the trained model during training\n",
    "joblib.dump(voice_classifier, \"voice_classifier_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n",
      "Non-voice detected.\n",
      "Recording...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.externals import joblib  # For model persistence\n",
    "\n",
    "# Load the pre-trained model\n",
    "voice_classifier = joblib.load(\"voice_classifier_model.pkl\")\n",
    "\n",
    "# Function to capture real-time audio\n",
    "def capture_audio(duration=5, sampling_rate=44100):\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(int(sampling_rate * duration), samplerate=sampling_rate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    return audio_data.flatten()\n",
    "\n",
    "# Function to predict voice using the trained model\n",
    "def predict_voice(audio_sample):\n",
    "    prediction = voice_classifier.predict([audio_sample])\n",
    "    return prediction[0]\n",
    "\n",
    "# Main program for real-time voice classification\n",
    "def real_time_voice_classification():\n",
    "    while True:\n",
    "        input(\"Press Enter and speak for a few seconds...\")\n",
    "\n",
    "        # Capture new audio\n",
    "        new_audio_sample = capture_audio()\n",
    "\n",
    "        # Predict if it's voice or non-voice\n",
    "        result = predict_voice(new_audio_sample)\n",
    "\n",
    "        if result == 1:\n",
    "            print(\"Voice detected!\")\n",
    "        else:\n",
    "            print(\"Non-voice detected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    real_time_voice_classification()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
